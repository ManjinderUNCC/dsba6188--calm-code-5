# -*- coding: utf-8 -*-
"""CalmCode 5

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1enPbsp8MaBrm3M7EI8PxMAO9FKCDGoZu

# Calm Code 5


Manjinder Sandhu

## Chains
"""

!wget https://calmcode.io/static/data/pokemon.json

import json
import pathlib

poke_dict = json.loads(pathlib.Path("pokemon.json").read_text())

poke_dict[:3]

class Clumper:
    def __init__(self, blob):
        self.blob = blob

    def keep(self, func):
        return [d for d in self.blob if func(d)]

Clumper(poke_dict).keep(lambda d: 'Grass' in d['type'])

class Clumper:
    def __init__(self, blob):
        self.blob = blob

    def keep(self, func):
        return Clumper([d for d in self.blob if func(d)])

(Clumper(poke_dict)
  .keep(lambda d: 'Grass' in d['type'])
  .keep(lambda d: d['hp'] < 60)
  .blob)

class Clumper:
    def __init__(self, blob):
        self.blob = blob

    def keep(self, *funcs):
        data = self.blob
        for func in funcs:
            data = [d for d in data if func(d)]
        return Clumper(data)

(Clumper(poke_dict)
  .keep(lambda d: 'Grass' in d['type'])
  .keep(lambda d: d['hp'] < 60)
  .blob)

class Clumper:
    def __init__(self, blob):
        self.blob = blob

    def keep(self, *funcs):
        data = self.blob
        for func in funcs:
            data = [d for d in data if func(d)]
        return Clumper(data)

    def head(self, n):
        return Clumper([self.blob[i] for i in range(n)])

    def tail(self, n):
        return Clumper([self.blob[-i] for i in range(1, n+1)])

(Clumper(poke_dict)
  .keep(lambda d: 'Grass' in d['type'],
        lambda d: d['hp'] < 60)
  .head(10)
  .blob)

class Clumper:
    def __init__(self, blob):
        self.blob = blob

    def keep(self, *funcs):
        data = self.blob
        for func in funcs:
            data = [d for d in data if func(d)]
        return Clumper(data)

    def head(self, n):
        return Clumper([self.blob[i] for i in range(n)])

    def tail(self, n):
        return Clumper([self.blob[-i] for i in range(1, n+1)])

    def select(self, *keys):
        return Clumper([{k: d[k] for k in keys} for d in self.blob])

(Clumper(poke_dict)
  .keep(lambda d: 'Grass' in d['type'],
        lambda d: d['hp'] < 60)
  .select('name', 'hp')
  .head(10)
  .blob)

class Clumper:
    def __init__(self, blob):
        self.blob = blob

    def keep(self, *funcs):
        data = self.blob
        for func in funcs:
            data = [d for d in data if func(d)]
        return Clumper(data)

    def head(self, n):
        return Clumper([self.blob[i] for i in range(n)])

    def tail(self, n):
        return Clumper([self.blob[-i] for i in range(1, n+1)])

    def select(self, *keys):
        return Clumper([{k: d[k] for k in keys} for d in self.blob])

    def mutate(self, **kwargs):
      data = self.blob
      for key, func in kwargs.items():
          for i in range(len(data)):
              data[i][key] = func(data[i])
      return Clumper(data)

(Clumper(poke_dict)
  .keep(lambda d: 'Grass' in d['type'],
        lambda d: d['hp'] < 60)
  .select('name', 'hp')
  .mutate(hp = lambda d: d['hp'] * 2,
          hp4 = lambda d: d['hp'] * 4)
  .blob)

class Clumper:
    def __init__(self, blob):
        self.blob = blob

    def keep(self, *funcs):
        data = self.blob
        for func in funcs:
            data = [d for d in data if func(d)]
        return Clumper(data)

    def head(self, n):
        return Clumper([self.blob[i] for i in range(n)])

    def tail(self, n):
        return Clumper([self.blob[-i] for i in range(1, n+1)])

    def select(self, *keys):
        return Clumper([{k: d[k] for k in keys} for d in self.blob])

    def mutate(self, **kwargs):
        data = self.blob
        for key, func in kwargs.items():
            for i in range(len(data)):
                data[i][key] = func(data[i])
        return Clumper(data)

    def sort(self, key, reverse=False):
        return Clumper(sorted(self.blob, key=key, reverse=reverse))

(Clumper(poke_dict)
    .keep(lambda d: 'Grass' in d['type'],
          lambda d: d['hp'] < 60)
    .select('name', 'hp')
    .sort(lambda d: d['hp'], reverse=True)
    .blob)

subset = []
for d in poke_dict:
  if "Grass" in d['type']:
    if d['hp']<60:
      subset.append({'hp':d['hp'],'name':d['name']})
sorted_subset = sorted(subset, key=lambda d: d['hp'], reverse=True)
sorted_subset[:15]

(Clumper(poke_dict)
  .keep(lambda d: 'Grass' in d['type'],
        lambda d: d['hp'] < 60)
  .mutate(ratio=lambda d: d['attack']/d['hp'])
  .select('name', 'ratio')
  .sort(lambda d: d['ratio'], reverse=True)
  .head(15)
  .blob)

"""# bad labels"""

!wget -P data/full_dataset/ https://storage.googleapis.com/gresearch/goemotions/data/full_dataset/goemotions_1.csv
!wget -P data/full_dataset/ https://storage.googleapis.com/gresearch/goemotions/data/full_dataset/goemotions_2.csv
!wget -P data/full_dataset/ https://storage.googleapis.com/gresearch/goemotions/data/full_dataset/goemotions_3.csv

import pandas as pd

from sklearn.pipeline import make_pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.feature_extraction.text import CountVectorizer

df = pd.read_csv("data/full_dataset/goemotions_1.csv")

df.columns

pd.set_option('display.max_colwidth', None)

df[['text', 'excitement']].loc[lambda d: d['excitement'] == 0].sample(2)

df['excitement'].value_counts()

X, y = df['text'], df['excitement']

pipe = make_pipeline(
    CountVectorizer(),
    LogisticRegression(class_weight='balanced', max_iter=1000)
)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# pipe.fit(X ,y)

pipe.predict_proba(X)

probas = pipe.predict_proba(X)[:, 0]
(df
  .loc[(probas > 0.45) & (probas < 0.55)]
  [['text', 'excitement']]
  .head(7))

df.loc[lambda d: d['excitement'] != pipe.predict(X)]

df.loc[lambda d: d['excitement'] != pipe.predict(X)].shape

def correct_class_confidence(X, y, mod):
    probas = mod.predict_proba(X)
    values = []
    for i, proba in enumerate(probas):
        proba_dict = {mod.classes_[j]: v for j, v in enumerate(proba)}
        values.append(proba_dict[y[i]])
    return values

(df
  .assign(confidence=correct_class_confidence(X, y, pipe))
  .loc[lambda d: pipe.predict(d['text']) != d['excitement']]
  [['text', 'excitement', 'confidence']]
  .sort_values("confidence")
  .loc[lambda d: d['excitement'] == 0]
  .head(20))

!python -m pip install cleanlab==1.0

from cleanlab.pruning import get_noise_indices

ordered_label_errors = get_noise_indices(
    s=y,
    psx=pipe.predict_proba(X),
    sorted_index_method='prob_given_label',
)

df.iloc[ordered_label_errors][['text', 'excitement']].head(20)

from cleanlab.classification import LearningWithNoisyLabels
from sklearn.linear_model import LogisticRegression

fresh_pipe = make_pipeline(
    CountVectorizer(),
    LogisticRegression(class_weight='balanced', max_iter=1000)
)
lnl = LearningWithNoisyLabels(clf=fresh_pipe)
lnl.fit(X=X, s=y.values)

new_pipe = make_pipeline(
    CountVectorizer(),
    LogisticRegression(class_weight='balanced', max_iter=1000)
)

new_pipe.fit(X=X, y=y)

df.loc[lnl.predict(X) != new_pipe.predict(X)][['text', 'excitement']].sample(5)